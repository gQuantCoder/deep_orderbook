{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import asyncio\n",
    "from deep_orderbook.shaper import ArrayShaper\n",
    "from deep_orderbook.config import ReplayConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_conf_3 = ReplayConfig(\n",
    "    markets=[\"ETH-BTC\", \"BTC-USD\", \"ETH-USD\"],\n",
    "    data_dir='data',\n",
    "    date_regexp='2024-08-04',\n",
    "    max_samples=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_orderbook.feeds.coinbase_feed import CoinbaseFeed\n",
    "from deep_orderbook.replayer import ParquetReplayer\n",
    "\n",
    "\n",
    "async def iter_sec(config: ReplayConfig):\n",
    "    async with CoinbaseFeed(\n",
    "        config=config,\n",
    "        replayer=ParquetReplayer(config=config),\n",
    "    ) as feed:\n",
    "        async for onesec in feed.one_second_iterator():\n",
    "            yield onesec\n",
    "\n",
    "\n",
    "async for onesec in iter_sec(config=replay_conf_3.but(max_samples=3)):\n",
    "    print(onesec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def iter_shapes(config: ReplayConfig):\n",
    "    symbol_shapers = {pair: ArrayShaper(zoom_frac=0.004) for pair in config.markets}\n",
    "    async for onesec in iter_sec(config=config):\n",
    "        yield {\n",
    "            market: await symbol_shapers[market].make_arr3d(onesec.symbols[market])\n",
    "            for market in config.markets\n",
    "        }\n",
    "\n",
    "\n",
    "async for shaped in iter_shapes(config=replay_conf_3.but(max_samples=1, skip_until_time=\"23:30\")):\n",
    "    for k, v in shaped.items():\n",
    "        print(f\"{k}: {v.shape}, values from {v.min()} to {v.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn_image as isns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "async def iter_gen_arrays(config: ReplayConfig):\n",
    "    async for shapes in iter_shapes(config=config.but(markets=[\"ETH-USD\"])):\n",
    "        yield shapes['ETH-USD'].transpose(1, 0, 2)\n",
    "\n",
    "\n",
    "async for arr in iter_gen_arrays(config=replay_conf_3.but(max_samples=100, skip_until_time=\"23:15\")):\n",
    "    im = arr.copy()\n",
    "    im[:,:,0] *= -0.2\n",
    "    im[:,:,1:3] *= 1e6\n",
    "    isns.imshow(im, origin='lower', cmap='coolwarm', vmin=-1, vmax=1, gray=True)\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def iter_shapes_t2l(config: ReplayConfig):\n",
    "    symbol_shaper = ArrayShaper(zoom_frac=0.004)\n",
    "    async for onesec in iter_sec(config=config):\n",
    "        yield [\n",
    "            await symbol_shaper.make_arr3d(onesec.symbols['ETH-USD']),\n",
    "            await symbol_shaper.build_time_level_trade(),\n",
    "            symbol_shaper.prices_array\n",
    "        ]\n",
    "\n",
    "async for shapes in iter_shapes_t2l(config=replay_conf_3.but(max_samples=1, skip_until_time=\"23:15\")):\n",
    "    print(shapes[0].shape, shapes[1].shape, shapes[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_orderbook.visu import Visualizer\n",
    "\n",
    "vis = Visualizer()\n",
    "\n",
    "\n",
    "# Define your asynchronous function to update the figure\n",
    "async def update_figure(config: ReplayConfig):\n",
    "    async for shaped, t2l, pxar in iter_shapes_t2l(config=config):\n",
    "        im_data = shaped.copy().transpose(1, 0, 2)\n",
    "        im_data[:, :, 0] *= -0.5\n",
    "        im_data[:, :, 1:3] *= 1e6\n",
    "        im_data = np.clip(im_data, -1, 1)\n",
    "        im_data = im_data.mean(axis=2)\n",
    "        t2l_data = np.clip(t2l[:, :, 0].T, -1, 1)\n",
    "\n",
    "        vis.update(books_z_data=im_data, level_reach_z_data=t2l_data, bidask=pxar)\n",
    "\n",
    "\n",
    "# Run the asynchronous function\n",
    "await update_figure(config=replay_conf_3.but(max_samples=100, skip_until_time=\"23:30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from holoviews.streams import Pipe\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Enable the Bokeh backend for HoloViews and initialize Panel\n",
    "hv.extension('bokeh')\n",
    "pn.extension()\n",
    "\n",
    "# Initialize Streams with appropriate empty data\n",
    "im_pipe = Pipe(data=np.zeros((10, 10)))        # For 'Books' heatmap\n",
    "t2l_pipe = Pipe(data=np.zeros((10, 10)))       # For 'Level Proximity' heatmap\n",
    "bidask_pipe = Pipe(data=np.empty((0, 2)))      # For 'Bid and Ask Price Levels'\n",
    "\n",
    "# Define HoloViews DynamicMaps for heatmaps\n",
    "im_dmap = hv.DynamicMap(lambda data: hv.Image(data).opts(invert_yaxis=True,\n",
    "    cmap='RdBu', colorbar=True, width=1200, height=200, title='Books',\n",
    "    xaxis=None, yaxis=None, ylim=(-0.5, 0.5),\n",
    "    axiswise=True, framewise=True, shared_axes=False\n",
    "), streams=[im_pipe])\n",
    "\n",
    "t2l_dmap = hv.DynamicMap(lambda data: hv.Image(data).opts(invert_yaxis=True,\n",
    "    cmap='Turbo', colorbar=True, width=1200, height=200, title='Level Proximity',\n",
    "    xaxis=None, yaxis=None, ylim=(-0.5, 0.5),\n",
    "    axiswise=True, framewise=True, shared_axes=False\n",
    "), streams=[t2l_pipe])\n",
    "\n",
    "def bidask_plot(data):\n",
    "    bid_curve = hv.Curve((data[:, 0]), 'bid').opts(color='green', line_width=2, framewise=True)\n",
    "    ask_curve = hv.Curve((data[:, 1]), 'ask').opts(color='red', line_width=2, framewise=True)\n",
    "    return (bid_curve * ask_curve).opts(width=1200, height=200, title='Bid and Ask', \n",
    "                                        # yaxis=None, xaxis='bottom'\n",
    "                                       )\n",
    "bidask_dmap = hv.DynamicMap(bidask_plot, streams=[bidask_pipe])\n",
    "\n",
    "# Layout the plots vertically using Panel\n",
    "dashboard = pn.Column(\n",
    "    pn.panel(im_dmap),\n",
    "    pn.panel(t2l_dmap),\n",
    "    pn.panel(bidask_dmap)\n",
    ")\n",
    "\n",
    "# Define the async update function\n",
    "async def run_updates():\n",
    "    async for shaped, t2l, pxar in iter_shapes_t2l(max_samples=100):\n",
    "        # if np.isnan(pxar).any().any():\n",
    "        #     pxar[np.isnan(pxar)] = np.nanmean(pxar)\n",
    "        # Process the 'Books' heatmap data\n",
    "        im_data = shaped.copy().transpose(1, 0, 2)\n",
    "        im_data[:, :, 0] *= -0.5\n",
    "        im_data[:, :, 1:3] *= 1e6\n",
    "        im_data = np.clip(im_data, -1, 1)\n",
    "        im_mean = im_data.mean(axis=2)\n",
    "\n",
    "        # Process the 'Level Proximity' heatmap data\n",
    "        t2l_data = np.clip(t2l[:, :, 0].T, -1, 1)\n",
    "\n",
    "        # Send data through the streams\n",
    "        im_pipe.send(im_mean)\n",
    "        t2l_pipe.send(t2l_data)\n",
    "        bidask_pipe.send(pxar)\n",
    "\n",
    "display(dashboard)\n",
    "await asyncio.sleep(0.1)\n",
    "\n",
    "# Start the async update in the background\n",
    "asyncio.create_task(run_updates())\n",
    "# dashboard.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from skimage import io\n",
    "img = io.imread('https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Crab_Nebula.jpg/240px-Crab_Nebula.jpg')\n",
    "fig = px.imshow(img)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\", logo=False)\n",
    "\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# Create a reactive HoloViews stream\n",
    "stream = hv.streams.Stream.define('ImageUpdate', data=None)()\n",
    "\n",
    "\n",
    "# Function to update the image\n",
    "async def update_image():\n",
    "    async for arr in iter_gen_arrays(max_samples=-1):\n",
    "        im = arr.copy()\n",
    "        im[:, :, 0] *= -0.5\n",
    "        im[:, :, 1:3] *= 1e6\n",
    "        im_display = im.mean(axis=2)\n",
    "\n",
    "        # Update the stream with the processed image\n",
    "        stream.event(data=im_display)\n",
    "        # await asyncio.sleep(0.1)\n",
    "\n",
    "\n",
    "# Start the asynchronous update\n",
    "asyncio.create_task(update_image())\n",
    "\n",
    "\n",
    "# Function to create the hv.Image with correct bounds\n",
    "def create_image(data):\n",
    "    if data is not None:\n",
    "        height, width = data.shape\n",
    "        return hv.Image(data, bounds=(0, 0, width, height))\n",
    "    else:\n",
    "        # Placeholder image if data is None\n",
    "        return hv.Image(np.zeros((128, 256)), bounds=(0, 0, 256, 128))\n",
    "\n",
    "\n",
    "# DynamicMap that updates with the stream\n",
    "dmap = hv.DynamicMap(create_image, streams=[stream])\n",
    "\n",
    "# Set display options\n",
    "dmap.opts(\n",
    "    cmap='RdBu',\n",
    "    frame_width=800,\n",
    "    aspect=256 / 128,\n",
    "    invert_yaxis=True,\n",
    "    xlabel='second',\n",
    "    ylabel='levels',\n",
    "    colorbar=True,\n",
    "    clim=(-1, 1),\n",
    ")\n",
    "\n",
    "# Display with Panel\n",
    "pn.panel(dmap).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display\n",
    "\n",
    "from learn.test_learn import train_and_predict\n",
    "\n",
    "async for books_array, time_levels, pxar, prediction, loss in train_and_predict(max_samples=10, epoch=1):\n",
    "    print(loss)\n",
    "\n",
    "# Define your asynchronous function to update the figure\n",
    "async def update_figure(max_samples=100, epoch=1):\n",
    "    # Initialize the figure with three subplots and adjust row heights\n",
    "    fig = make_subplots(\n",
    "        rows=5, cols=1,\n",
    "        subplot_titles=(\"Books\", \"Level Proximity\", \"Bid and Ask Price Levels\"),\n",
    "        vertical_spacing=0.05,\n",
    "        row_heights=[0.2, 0.2, 0.2, 0.2, 0.2]  # Adjust the relative heights of the rows\n",
    "    )\n",
    "\n",
    "    # Increase the overall figure height\n",
    "    fig.update_layout(\n",
    "        height=600,  # Adjusted for three subplots\n",
    "        width=1200,\n",
    "        margin=dict(t=50, b=50, l=50, r=50),\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    # Create the figure widget\n",
    "    fig_widget = go.FigureWidget(fig)\n",
    "    display(fig_widget)\n",
    "\n",
    "    # Initialize empty traces for heatmaps\n",
    "    im_trace = go.Heatmap(\n",
    "        z=np.zeros((10, 10)),\n",
    "        colorscale='RdBu',\n",
    "        zmin=-1, zmax=1,\n",
    "        showscale=False\n",
    "    )\n",
    "    t2l_trace = go.Heatmap(\n",
    "        z=np.zeros((10, 10)),\n",
    "        colorscale='Turbo',\n",
    "        zmin=0, zmax=1,\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "    # Initialize line traces for bid and ask price levels\n",
    "    bid_trace = go.Scatter(\n",
    "        x=[], y=[],\n",
    "        mode='lines',\n",
    "        line=dict(color='green'),\n",
    "        showlegend=False\n",
    "    )\n",
    "    ask_trace = go.Scatter(\n",
    "        x=[], y=[],\n",
    "        mode='lines',\n",
    "        line=dict(color='red'),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    pred_trace = go.Heatmap(\n",
    "        z=np.zeros((10, 10)),\n",
    "        colorscale='Turbo',\n",
    "        zmin=0, zmax=1,\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "    # Initialize line traces for bid and ask price levels\n",
    "    loss_trace = go.Scatter(\n",
    "        x=[], y=[],\n",
    "        mode='lines',\n",
    "        line=dict(color='green'),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    # Add traces to the figure widget\n",
    "    fig_widget.add_trace(im_trace, row=1, col=1)\n",
    "    fig_widget.add_trace(t2l_trace, row=2, col=1)\n",
    "    fig_widget.add_trace(bid_trace, row=3, col=1)\n",
    "    fig_widget.add_trace(ask_trace, row=3, col=1)\n",
    "    fig_widget.add_trace(pred_trace, row=4, col=1)\n",
    "    fig_widget.add_trace(loss_trace, row=5, col=1)\n",
    "\n",
    "    # Asynchronous loop to update the figure\n",
    "    losses = []\n",
    "    async for shaped, t2l, pxar, prediction, loss in train_and_predict(max_samples=max_samples, epoch=epoch):\n",
    "        # Process your data for heatmaps\n",
    "        im_data = shaped.copy().transpose(1, 0, 2)\n",
    "        im_data[:, :, 0] *= -0.5\n",
    "        im_data[:, :, 1:3] *= 1e6\n",
    "        im_data = np.clip(im_data, -1, 1)\n",
    "        t2l_data = np.clip(t2l[:, :, 0].T, -1, 1)\n",
    "\n",
    "        # Extract bid and ask prices from pxar\n",
    "        bid_prices = pxar[:, 0]\n",
    "        ask_prices = pxar[:, 1]\n",
    "        times = np.arange(len(bid_prices))  # Assuming levels from 0 to 511\n",
    "\n",
    "        pred_shape = prediction.reshape(t2l.shape).transpose(1, 0, 2)\n",
    "        pred_shape = np.clip(pred_shape[:, :, 0], -1, 1)\n",
    "        losses.append(loss)\n",
    "        losses =losses[-512:]\n",
    "\n",
    "        # Update the figure widget traces\n",
    "        with fig_widget.batch_update():\n",
    "            # Update heatmaps\n",
    "            fig_widget.data[0].z = im_data.mean(axis=2)\n",
    "            fig_widget.data[1].z = t2l_data\n",
    "\n",
    "            # Update bid and ask price traces\n",
    "            fig_widget.data[2].x = times\n",
    "            fig_widget.data[2].y = bid_prices\n",
    "            fig_widget.data[3].x = times\n",
    "            fig_widget.data[3].y = ask_prices\n",
    "\n",
    "            # Update prediction heatmap\n",
    "            fig_widget.data[4].z = pred_shape\n",
    "            fig_widget.data[5].x = np.arange(len(losses))\n",
    "            fig_widget.data[5].y = losses\n",
    "\n",
    "# Run the asynchronous function\n",
    "await update_figure(max_samples=100000, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
